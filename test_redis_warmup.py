import httpx
import asyncio
import sys
import logging
import time
import os 
import json 
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
from cache_manager import get_redis_connection
from redis.asyncio import Redis as AsyncRedis 
from config import REDIS_TASK_QUEUE_KEY, WORKER_LOCK_KEY, WORKER_LOCK_VALUE


# --- 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ .env ---
load_dotenv()  
BASE_URL = os.environ.get("BASE_URL", "http://127.0.0.1:8000") 
SECRET_TOKEN = os.environ.get("SECRET_TOKEN") 

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
POLL_INTERVAL_SEC = 5  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫
MAX_WAIT_MINUTES_PER_TASK = 15
CACHE_POLL_INTERVAL_SEC = 3
MAX_CACHE_WAIT_SEC = 60
# -----------------

# --- –ó–∞–¥–∞—á–∏ –¥–ª—è "–ø—Ä–æ–≥—Ä–µ–≤–∞" ---
TASKS_TO_RUN = ["global_fr", "1h", "4h", "8h", "12h", "1d"] 
CACHE_KEYS_TO_VALIDATE = ["global_fr", "1h", "4h", "8h", "12h", "1d"]
# ---------------------------

# (–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
log = logging.getLogger("CACHE_WARMUP")

# (–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö)
EXPECTED_CANDLE_KEYS = [
    "openTime", "openPrice", "highPrice", "lowPrice", "closePrice", "volume",
    "volumeDelta"
]
EXPECTED_TOP_LEVEL_KEYS = [
    "openTime", "closeTime", "timeframe", "audit_report", "data"
]
EXPECTED_COIN_DATA_KEYS = [
    "symbol", "exchanges", "data"
]


async def _cleanup_all_cache_keys(redis_conn: AsyncRedis, log_prefix: str):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç –≤—Å–µ –∫–ª—é—á–∏ –∫—ç—à–∞ (cache:*) –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º."""
    log.info(f"{log_prefix} --- –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –ö–≠–®–ê (cache:*) ---")
    
    try:
        keys_to_delete_cache = await redis_conn.keys("cache:*")
        
        keys_to_delete_all = keys_to_delete_cache + [WORKER_LOCK_KEY, REDIS_TASK_QUEUE_KEY]
        keys_to_delete_all = [key.decode('utf-8') if isinstance(key, bytes) else key for key in keys_to_delete_all]
        keys_to_delete_all = list(set(keys_to_delete_all)) # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ
        
        deleted_count = 0
        if keys_to_delete_all:
            deleted_count = await redis_conn.delete(*keys_to_delete_all)
            
        log.info(f"{log_prefix} –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –∫–ª—é—á–µ–π –∫—ç—à–∞/–±–ª–æ–∫–∏—Ä–æ–≤–æ–∫/–æ—á–µ—Ä–µ–¥–∏.")
        
    except Exception as e:
        log.error(f"{log_prefix} –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Redis: {e}", exc_info=True)
    
    try:
        await redis_conn.delete(WORKER_LOCK_KEY, REDIS_TASK_QUEUE_KEY)
        log.info(f"{log_prefix} –û—á–∏—â–µ–Ω—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ –∏ –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á.")
    except Exception as e:
        log.error(f"{log_prefix} –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫/–æ—á–µ—Ä–µ–¥–∏: {e}", exc_info=True)

    log.info("--- (Redis –æ—á–∏—â–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º) ---")


async def wait_for_cache_to_appear(client: httpx.AsyncClient, cache_key: str, redis_conn: AsyncRedis) -> bool:
    """
    –û–ø—Ä–∞—à–∏–≤–∞–µ—Ç Redis –Ω–∞–ø—Ä—è–º—É—é, –ø–æ–∫–∞ –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –∫—ç—à.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –ø–æ—è–≤–∏–ª—Å—è, False –µ—Å–ª–∏ —Ç–∞–π–º–∞—É—Ç.
    """
    log.info(f"[CACHE_WAIT] üîç –û–∂–∏–¥–∞—é –ø–æ—è–≤–ª–µ–Ω–∏—è 'cache:{cache_key}' –≤ Redis (–º–∞–∫—Å {MAX_CACHE_WAIT_SEC} —Å–µ–∫)...")
    start_time = time.time()
    
    full_key = f"cache:{cache_key}"
    attempt = 0
    
    while True:
        attempt += 1
        elapsed = time.time() - start_time
        
        if elapsed > MAX_CACHE_WAIT_SEC:
            log.error(f"[CACHE_WAIT] ‚ùå –¢–∞–π–º–∞—É—Ç! –ö—ç—à '{full_key}' –Ω–µ –ø–æ—è–≤–∏–ª—Å—è –∑–∞ {MAX_CACHE_WAIT_SEC} —Å–µ–∫.")
            return False
        
        try:
            exists = await redis_conn.exists(full_key)
            
            if exists:
                log.info(f"[CACHE_WAIT] ‚úÖ –ö—ç—à '{full_key}' –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ Redis! (–ø–æ–ø—ã—Ç–∫–∞ #{attempt}, {elapsed:.1f} —Å–µ–∫)")
                return True
            else:
                log.info(f"[CACHE_WAIT] ... –ü–æ–ø—ã—Ç–∫–∞ #{attempt}: '{full_key}' –µ—â—ë –Ω–µ—Ç. –ñ–¥—É {CACHE_POLL_INTERVAL_SEC} —Å–µ–∫...")
                await asyncio.sleep(CACHE_POLL_INTERVAL_SEC)
                
        except Exception as e:
            log.error(f"[CACHE_WAIT] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ Redis: {e}")
            await asyncio.sleep(CACHE_POLL_INTERVAL_SEC)


# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ1 –∏ ‚Ññ2: –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥–∏–∫–∏ –æ–∂–∏–¥–∞–Ω–∏—è ---
async def wait_for_worker_to_be_free(redis_conn: AsyncRedis, task_name: str):
    """
    –û–ø—Ä–∞—à–∏–≤–∞–µ—Ç Redis, –∏—Å–ø–æ–ª—å–∑—É—è –¥–≤—É—Ö—Ñ–∞–∑–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É,
    —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ù–ê–® –≤–æ—Ä–∫–µ—Ä (lock='processing') –≤–∑—è–ª –∏ –∑–∞–≤–µ—Ä—à–∏–ª –∑–∞–¥–∞—á—É.
    """
    log.info(f"--- –û–∂–∏–¥–∞—é –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ '{task_name}' (–æ–ø—Ä–æ—Å Redis {WORKER_LOCK_KEY} –∫–∞–∂–¥—ã–µ {POLL_INTERVAL_SEC} —Å–µ–∫)...")
    max_wait_time_sec = MAX_WAIT_MINUTES_PER_TASK * 60
    
    if not redis_conn:
        log.error("üí• [FAIL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")
        raise ConnectionError("Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ wait_for_worker_to_be_free")
        
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ2: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è 'init_check' ---
    # (–ú—ã –Ω–µ –º–æ–∂–µ–º –∂–¥–∞—Ç—å 'processing', —Ç.–∫. –∑–∞–¥–∞—á–∞ –µ—â–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.
    # –ú—ã –ø—Ä–æ—Å—Ç–æ –∂–¥–µ–º, –ø–æ–∫–∞ –≤—Å–µ "–∑–æ–º–±–∏" (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å) –Ω–µ —É–π–¥—É—Ç)
    if task_name == "init_check":
        log.info("... [init_check] –û–∂–∏–¥–∞—é, –ø–æ–∫–∞ –õ–Æ–ë–ê–Ø –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –±—É–¥–µ—Ç —Å–Ω—è—Ç–∞ (–§–∞–∑–∞ 2)...")
        phase1_start_time = time.time()
        while time.time() - phase1_start_time < max_wait_time_sec:
            try:
                lock_status_bytes = await redis_conn.get(WORKER_LOCK_KEY)
                lock_status = lock_status_bytes.decode('utf-8') if lock_status_bytes else None
                
                if lock_status is None:
                    log.info(f"‚úÖ [init_check] –í–æ—Ä–∫–µ—Ä —Å–≤–æ–±–æ–¥–µ–Ω (Lock=None).")
                    return # –£–°–ü–ï–•
                else:
                    log.warning(f"... [init_check] –í–æ—Ä–∫–µ—Ä (–≤–æ–∑–º–æ–∂–Ω–æ, '–∑–æ–º–±–∏') –∑–∞–Ω—è—Ç (Lock='{lock_status}'). –ñ–¥—É {POLL_INTERVAL_SEC} —Å–µ–∫...")
                    await asyncio.sleep(POLL_INTERVAL_SEC)
                    
            except Exception as e:
                log.error(f"[init_check] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–æ—Å–µ Redis (lock): {e}", exc_info=False)
                await asyncio.sleep(POLL_INTERVAL_SEC)
        
        raise TimeoutError(f"–¢–∞–π–º–∞—É—Ç [init_check]! –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –±—ã–ª–∞ —Å–Ω—è—Ç–∞ –∑–∞ {max_wait_time_sec} —Å–µ–∫.")
    # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ‚Ññ2 ---

    # --- –§–∞–∑–∞ 1: –ñ–¥–µ–º, –ø–æ–∫–∞ –ù–ê–® –≤–æ—Ä–∫–µ—Ä (processing) –ó–ê–•–í–ê–¢–ò–¢ –∑–∞–¥–∞—á—É ---
    log.info(f"... –§–∞–∑–∞ 1: –û–∂–∏–¥–∞—é, –ø–æ–∫–∞ '{WORKER_LOCK_VALUE}' –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –≤ {WORKER_LOCK_KEY} (–ú–∞–∫—Å {max_wait_time_sec} —Å–µ–∫)...")
    phase1_start_time = time.time()
    task_taken = False
    
    while time.time() - phase1_start_time < max_wait_time_sec:
        try:
            lock_status_bytes = await redis_conn.get(WORKER_LOCK_KEY)
            lock_status = lock_status_bytes.decode('utf-8') if lock_status_bytes else None
            
            if lock_status == WORKER_LOCK_VALUE:
                log.info(f"‚úÖ [–§–∞–∑–∞ 1] –ù–ê–® –≤–æ—Ä–∫–µ—Ä –∑–∞—Ö–≤–∞—Ç–∏–ª –∑–∞–¥–∞—á—É (Lock='{lock_status}'). –ü–µ—Ä–µ—Ö–æ–∂—É –∫ –§–∞–∑–µ 2.")
                task_taken = True
                break
            elif lock_status is not None:
                # --- –≠—Ç–æ "—Ñ–∞–Ω—Ç–æ–º–Ω—ã–π" –ª–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, busy_by_...) ---
                log.warning(f"... [–§–∞–∑–∞ 1] '–§–∞–Ω—Ç–æ–º–Ω—ã–π' –≤–æ—Ä–∫–µ—Ä –∑–∞–Ω—è—Ç (Lock='{lock_status}'). –ñ–¥—É, –ø–æ–∫–∞ –æ–Ω –æ—Å–≤–æ–±–æ–¥–∏—Ç...")
                await asyncio.sleep(POLL_INTERVAL_SEC)
            else:
                # Lock is None,
                log.info(f"... [–§–∞–∑–∞ 1] –í–æ—Ä–∫–µ—Ä —Å–≤–æ–±–æ–¥–µ–Ω (Lock=None). –û–∂–∏–¥–∞—é –∑–∞—Ö–≤–∞—Ç–∞ –∑–∞–¥–∞—á–∏ '{task_name}'... –ñ–¥—É {POLL_INTERVAL_SEC} —Å–µ–∫...")
                await asyncio.sleep(POLL_INTERVAL_SEC)

        except Exception as e:
            log.error(f"[–§–∞–∑–∞ 1] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–æ—Å–µ Redis (lock): {e}", exc_info=False)
            await asyncio.sleep(POLL_INTERVAL_SEC)
            
    if not task_taken:
         raise TimeoutError(f"–¢–∞–π–º–∞—É—Ç –§–∞–∑—ã 1! –ù–ê–® –≤–æ—Ä–∫–µ—Ä (lock='{WORKER_LOCK_VALUE}') –Ω–µ –∑–∞—Ö–≤–∞—Ç–∏–ª –∑–∞–¥–∞—á—É '{task_name}' –∑–∞ {max_wait_time_sec} —Å–µ–∫.")

    # --- –§–∞–∑–∞ 2: –ñ–¥–µ–º, –ø–æ–∫–∞ –ù–ê–® –≤–æ—Ä–∫–µ—Ä (processing) –û–°–í–û–ë–û–î–ò–¢ –∑–∞–¥–∞—á—É ---
    log.info(f"... –§–∞–∑–∞ 2: –û–∂–∏–¥–∞—é, –ø–æ–∫–∞ '{WORKER_LOCK_VALUE}' –Ω–µ –∏—Å—á–µ–∑–Ω–µ—Ç (–≤–æ—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–∏—Ç —Ä–∞–±–æ—Ç—É)...")
    phase2_start_time = time.time()
    
    while time.time() - phase2_start_time < max_wait_time_sec:
        try:
            lock_status_bytes = await redis_conn.get(WORKER_LOCK_KEY)
            lock_status = lock_status_bytes.decode('utf-8') if lock_status_bytes else None
            
            if lock_status == WORKER_LOCK_VALUE:
                log.info(f"... [–§–∞–∑–∞ 2] –ù–ê–® –≤–æ—Ä–∫–µ—Ä –≤—Å–µ –µ—â–µ –∑–∞–Ω—è—Ç (Lock='{lock_status}'). –ñ–¥—É {POLL_INTERVAL_SEC} —Å–µ–∫...")
                await asyncio.sleep(POLL_INTERVAL_SEC)
            else:
                log.info(f"‚úÖ [–§–∞–∑–∞ 2] –ù–ê–® –≤–æ—Ä–∫–µ—Ä –æ—Å–≤–æ–±–æ–¥–∏–ª—Å—è (Lock='{lock_status}'). –ó–∞–¥–∞—á–∞ '{task_name}' –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.")
                return # –£–°–ü–ï–•

        except Exception as e:
            log.error(f"[–§–∞–∑–∞ 2] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–æ—Å–µ Redis (lock): {e}", exc_info=False)
            await asyncio.sleep(POLL_INTERVAL_SEC)

    raise TimeoutError(f"–¢–∞–π–º–∞—É—Ç –§–∞–∑—ã 2! –ù–ê–® –≤–æ—Ä–∫–µ—Ä (lock='{WORKER_LOCK_VALUE}') –Ω–µ –æ—Å–≤–æ–±–æ–¥–∏–ª –∑–∞–¥–∞—á—É '{task_name}' –∑–∞ {max_wait_time_sec} —Å–µ–∫.")
# --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ‚Ññ1 ---


async def post_task(client: httpx.AsyncClient, task_name: str, redis_conn: AsyncRedis):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç 1 –∑–∞–¥–∞—á—É (Klines –∏–ª–∏ FR) –Ω–∞ —Å–µ—Ä–≤–µ—Ä.
    """
    if task_name == "global_fr":
        if not SECRET_TOKEN: 
            log.error("üí• [FAIL] SECRET_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env. –ù–µ –º–æ–≥—É –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É 'global_fr'.")
            raise ValueError("SECRET_TOKEN not set")
            
        log.info("–ó–∞–ø—É—Å–∫–∞—é –∑–∞–¥–∞—á—É 'global_fr' (POST /internal/update-fr)...")
        headers = {"Authorization": f"Bearer {SECRET_TOKEN}"}
        response = await client.post("/internal/update-fr", headers=headers)
    
    else:
        cache_key_to_clear = f"cache:{task_name}"
        log.info(f"–û—á–∏—â–∞—é '{cache_key_to_clear}', —á—Ç–æ–±—ã API –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ...")
        await redis_conn.delete(cache_key_to_clear)
        
        log.info(f"–ó–∞–ø—É—Å–∫–∞—é –∑–∞–¥–∞—á—É '{task_name}' (POST /get-market-data)...")
        response = await client.post("/get-market-data", json={"timeframes": [task_name]})

    if response.status_code == 202:
        log.info(f"‚úÖ [OK] –ó–∞–¥–∞—á–∞ '{task_name}' –ø—Ä–∏–Ω—è—Ç–∞ –≤ –æ—á–µ—Ä–µ–¥—å.")
    elif response.status_code == 409:
        log.warning(f"–í–æ—Ä–∫–µ—Ä —É–∂–µ –±—ã–ª –∑–∞–Ω—è—Ç (409). –û–∂–∏–¥–∞—é –µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
    else:
        response.raise_for_status() 


def validate_cache_data(data: dict, key: str):
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–µ—à–∞ –±–µ–∑ –≤—ã–≤–æ–¥–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ –ª–æ–≥–∏
    """
    log.info(f"--- üî¨ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è 'cache:{key}' ---")
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ 'global_fr'
    if key == 'global_fr':
        data = data.get('data', {})
        if not isinstance(data, dict):
            raise ValueError(f"'global_fr' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º (dict) –ø–æ—Å–ª–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏")
        
        if not data:
            log.warning(f"Validation WARNING: 'cache:{key}' –ø—É—Å—Ç (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö).")
            return
            
        first_key = list(data.keys())[0]
        first_value = data[first_key]
        
        if not isinstance(first_key, str):
            raise ValueError("–ö–ª—é—á –≤ 'global_fr' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π (—Å–∏–º–≤–æ–ª–æ–º)")
        
        if not isinstance(first_value, list):
            raise ValueError("–ó–Ω–∞—á–µ–Ω–∏–µ –≤ 'global_fr' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º (list)")
        
        if not first_value:
             log.warning(f"Validation WARNING: 'cache:{key}' —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è {first_key}.")
             return
        
        if "openTime" not in first_value[0]:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç 'openTime' –≤ –¥–∞–Ω–Ω—ã—Ö global_fr")
        
        if "fundingRate" not in first_value[0]:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç 'fundingRate' –≤ –¥–∞–Ω–Ω—ã—Ö global_fr")
        
        log.info(f"‚úÖ [OK] –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è 'cache:{key}' –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.")
        return

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ Klines (1h, 4h, 8h, 12h, 1d)
    for top_key in EXPECTED_TOP_LEVEL_KEYS:
        if top_key not in data:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è '{top_key}' –≤ –æ—Ç–≤–µ—Ç–µ {key}")
    
    if data["timeframe"] != key:
        raise ValueError(f"Timeframe –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –æ–∂–∏–¥–∞–ª—Å—è {key}, –ø–æ–ª—É—á–µ–Ω {data['timeframe']}")
    
    if not isinstance(data["data"], list):
        raise ValueError(f"'data' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –ø–æ–ª—É—á–µ–Ω {type(data['data'])}")
    
    if not data["data"]:
        log.warning(f"Validation WARNING: 'cache:{key}' —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ 'data'. –ê—É–¥–∏—Ç: {data['audit_report']}")
        return

    log.info(f"–ù–∞–π–¥–µ–Ω–æ {len(data['data'])} –º–æ–Ω–µ—Ç –≤ 'data' (–ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é).")

    coin_data = data["data"][0]
    for coin_key in EXPECTED_COIN_DATA_KEYS:
        if coin_key not in coin_data:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á '{coin_key}' –≤ coin_data (data[0])")
    
    if not isinstance(coin_data["data"], list):
        raise ValueError(f"coin_data['data'] –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
    
    if len(coin_data["data"]) == 0:
        raise ValueError(f"–°–ø–∏—Å–æ–∫ 'data' –≤–Ω—É—Ç—Ä–∏ –º–æ–Ω–µ—Ç—ã {coin_data['symbol']} –ø—É—Å—Ç")

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ü–û–°–õ–ï–î–ù–ï–ô —Å–≤–µ—á–∏
    candle = coin_data["data"][-1]
    open_time = candle.get('openTime', 'UNKNOWN')
    log.info(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–∏ –ü–û–°–õ–ï–î–ù–ï–ô —Å–≤–µ—á–∏ (OpenTime: {open_time})...")
    
    for candle_key in EXPECTED_CANDLE_KEYS:
        if candle_key not in candle:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª—é—á Klines '{candle_key}' –≤ —Å–≤–µ—á–µ")
    
    if "openInterest" not in candle:
        raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'openInterest' (–º–æ–∂–µ—Ç –±—ã—Ç—å None)")
    
    if "fundingRate" not in candle:
        raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'fundingRate' (–º–æ–∂–µ—Ç –±—ã—Ç—å None)")

    log.info(f"‚úÖ [OK] –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è 'cache:{key}' –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.")


async def run_cache_warmup():
    """
    –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç "–ø—Ä–æ–≥—Ä–µ–≤–∞" –∫—ç—à–∞.
    """
    total_start_time = time.time()
    log.info("--- üöÄ –ù–ê–ß–ò–ù–ê–Æ –ü–†–û–ì–†–ï–í –ö–≠–®–ê ---")
    log.info(f"–¶–µ–ª—å: {BASE_URL}")
    log.info(f"–ó–∞–¥–∞—á–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {TASKS_TO_RUN}")

    redis_conn = await get_redis_connection()
    if not redis_conn:
        log.error("üí• [FAIL] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≥—Ä–µ–≤ –æ—Ç–º–µ–Ω–µ–Ω.")
        sys.exit(1)
    
    await _cleanup_all_cache_keys(redis_conn, "[PRE_TEST]")

    async with httpx.AsyncClient(base_url=BASE_URL, timeout=120.0) as client:
        
        try:
            response = await client.get("/health") 
            response.raise_for_status()
            log.info("‚úÖ [OK] –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω.")
        except (httpx.ConnectError, httpx.HTTPStatusError) as e:
            log.error(f"üí• [FAIL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É: {e}")
            return

        try:
            # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ2: –≠—Ç–æ—Ç –≤—ã–∑–æ–≤ —Ç–µ–ø–µ—Ä—å –∂–¥–µ—Ç, –ø–æ–∫–∞ –í–°–ï (–≤–∫–ª—é—á–∞—è –∑–æ–º–±–∏) –Ω–µ –∑–∞–∫–æ–Ω—á–∞—Ç ---
            await wait_for_worker_to_be_free(redis_conn, "init_check") 
            log.info("--- (–í–æ—Ä–∫–µ—Ä —Å–≤–æ–±–æ–¥–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º) ---")
        except TimeoutError as e:
            log.error(f"üí• [FAIL] {e}")
            log.error("–í–æ—Ä–∫–µ—Ä –±—ã–ª –∑–∞–Ω—è—Ç –µ—â–µ –¥–æ –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞. –ü—Ä–µ—Ä—ã–≤–∞—é.")
            return

        # --- –®–∞–≥ 3: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–¥–∞—á (ENRICH REDIS) ---
        for task in TASKS_TO_RUN:
            task_start_time = time.time()
            log.info(f"--- üî• –ó–∞–ø—É—Å–∫–∞—é –∑–∞–¥–∞—á—É: {task} ---")
            
            try:
                await post_task(client, task, redis_conn)
                
                # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ1: –≠—Ç–æ—Ç –≤—ã–∑–æ–≤ —Ç–µ–ø–µ—Ä—å –ñ–î–ï–¢, –ø–æ–∫–∞ –ù–ê–® –≤–æ—Ä–∫–µ—Ä –Ω–µ –ó–ê–í–ï–†–®–ò–¢ ---
                await wait_for_worker_to_be_free(redis_conn, task)
                
                log.info(f"[POST_TASK] ‚è≥ –ó–∞–¥–∞—á–∞ '{task}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤–æ—Ä–∫–µ—Ä–æ–º. –û–∂–∏–¥–∞—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Redis...")
                cache_appeared = await wait_for_cache_to_appear(client, task, redis_conn)
                
                if not cache_appeared:
                    log.error(f"[POST_TASK] ‚ùå –ö—ç—à '{task}' –ù–ï –ø–æ—è–≤–∏–ª—Å—è –≤ Redis –∑–∞ {MAX_CACHE_WAIT_SEC} —Å–µ–∫!")
                    log.error("–ü—Ä–æ–≥—Ä–µ–≤ –∫—ç—à–∞ –ø—Ä–µ—Ä–≤–∞–Ω.")
                    return
                
                task_end_time = time.time()
                log.info(f"--- ‚úÖ –ó–∞–¥–∞—á–∞ '{task}' –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê –∑–∞ {(task_end_time - task_start_time):.2f} —Å–µ–∫. ---")

            except Exception as e:
                log.error(f"üí• [FAIL] –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ '{task}': {e}")
                log.error("–ü—Ä–æ–≥—Ä–µ–≤ –∫—ç—à–∞ –ø—Ä–µ—Ä–≤–∞–Ω.")
                return

        log.info("--- üèÜ –ü–†–û–ì–†–ï–í –ö–≠–®–ê (–ó–ê–î–ê–ß–ò) –ó–ê–í–ï–†–®–ï–ù ---")
        
        # --- –®–∞–≥ 4: –í–∞–ª–∏–¥–∞—Ü–∏—è (CHECK ALL ENDPOINTS) ---
        log.info("--- üî¨ –ù–∞—á–∏–Ω–∞—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Å–µ—Ö –∫—ç—à–µ–π (/get-cache/...) ---")
        all_valid = True
        
        for key in CACHE_KEYS_TO_VALIDATE:
            try:
                log.info(f"–ó–∞–≥—Ä—É–∂–∞—é 'cache:{key}'...")
                response = await client.get(f"/get-cache/{key}") 
                response.raise_for_status() 
                
                validate_cache_data(response.json(), key)
                
            except Exception as e:
                log.error(f"üí• [FAIL] –û–®–ò–ë–ö–ê –í–ê–õ–ò–î–ê–¶–ò–ò –¥–ª—è 'cache:{key}': {e}", exc_info=True)
                all_valid = False

        # --- –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç ---
        if all_valid:
            log.info("--- üèÜüèÜüèÜ E2E –¢–ï–°–¢ –ò –ü–†–û–ì–†–ï–í –ö–≠–®–ê –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–´! ---")
        else:
            log.error("--- üí• E2E –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù. –°–º–æ—Ç—Ä–∏ –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—ã—à–µ. ---")
            
    total_end_time = time.time()
    log.info(f"--- –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {(total_end_time - total_start_time):.2f} —Å–µ–∫. ---")


if __name__ == "__main__":
    try:
        asyncio.run(run_cache_warmup())
    except KeyboardInterrupt:
        log.warning("–ü—Ä–æ–≥—Ä–µ–≤ –∫—ç—à–∞ –ø—Ä–µ—Ä–≤–∞–Ω –≤—Ä—É—á–Ω—É—é.")